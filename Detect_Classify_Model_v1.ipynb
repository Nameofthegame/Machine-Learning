{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources**\n",
    "\n",
    "\n",
    "* *R-CNN object detection with Keras, TensorFlow, and Deep Learning*. Rosebrock, Adrian. *PyImageSearch.com*, 2020, July 13. https://www.pyimagesearch.com/2020/07/13/r-cnn-object-detection-with-keras-tensorflow-and-deep-learning/\n",
    "\n",
    "\n",
    "* *Custom Object Detection Using Keras and OpenCV*. Mohebban, Samuel. *TowardsDataScience.com*, 2020, Sept. 9. https://towardsdatascience.com/how-to-build-a-weapon-detection-system-using-keras-and-opencv-67b19234e3dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np \n",
    "import cv2\n",
    "from keras.preprocessing import image \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from skimage.segmentation import mark_boundaries \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D, Dense, Dropout, Flatten \n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_value(path, dim): \n",
    "    '''This function will read an image and convert to a specified version and resize depending on which algorithm is being used. '''\n",
    "    img = image.load_img(path, target_size = dim)\n",
    "    img = image.img_to_array(img)\n",
    "    return img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(img_paths, dim): \n",
    "    '''This fucntion takes a list of image paths and returns the np array corresponding to each image.  It also takes the dim and whether edge is specified in order to pass it to another function to apply these parameters.  This function uses get_image_value to perform these operations'''\n",
    "    final_array = []\n",
    "    from tqdm import tqdm\n",
    "    for path in tqdm(img_paths):\n",
    "        img = get_image_value(path, dim)\n",
    "        final_array.append(img)\n",
    "    final_array = np.array(final_array)  \n",
    "    return final_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tts():\n",
    "    '''This function will create a train test split''' \n",
    "    DIM =  (150,150) \n",
    "    np.random.seed(10)        \n",
    "    pistol_paths = [f'C:/Users/jbmut/AI Projects/GunFree/Other Datasets/Separated/FinalImages/Pistol/{i}' for i in os.listdir('C:/Users/jbmut/AI Projects/GunFree/Other Datasets/Separated/FinalImages/Pistol')] \n",
    "    pistol_labels = [1 for i in range(len(pistol_paths))]\n",
    "    rifle_paths = [f'C:/Users/jbmut/AI Projects/GunFree/Other Datasets/Separated/FinalImages/Rifle/{i}' for i in os.listdir('C:/Users/jbmut/AI Projects/GunFree/Other Datasets/Separated/FinalImages/Rifle')] \n",
    "    rifle_labels = [2 for i in range(len(rifle_paths))]    \n",
    "    neg_paths = [f'C:/Users/jbmut/AI Projects/GunFree/Other Datasets/Separated/FinalImages/NoWeapon/{i}' for i in os.listdir('C:/Users/jbmut/AI Projects/GunFree/Other Datasets/Separated/FinalImages/NoWeapon')]\n",
    "    np.random.shuffle(neg_paths)\n",
    "    neg_paths = neg_paths[:len(pistol_paths)- 500]\n",
    "    neg_labels = [0 for i in range(len(neg_paths))]\n",
    "\n",
    "    np.random.shuffle(pistol_paths)\n",
    "    pistol_paths = pistol_paths[:len(rifle_paths)+150]\n",
    "    neg_paths = neg_paths[:len(rifle_paths)+150]\n",
    "\n",
    "    pistol_labels = [1 for i in range(len(pistol_paths))]\n",
    "    rifle_labels = [2 for i in range(len(rifle_paths))]\n",
    "    neg_labels = [0 for i in range(len(neg_paths))]\n",
    "    paths = pistol_paths + rifle_paths + neg_paths\n",
    "    labels = pistol_labels + rifle_labels + neg_labels\n",
    "    x_train, x_test, y_train, y_test = train_test_split(paths, labels, stratify = labels, train_size = .90, random_state = 10)\n",
    "\n",
    "    new_x_train = get_img_array(x_train, DIM)\n",
    "    new_x_test = get_img_array(x_test, DIM)\n",
    "    \n",
    "    print('Train Value Counts')\n",
    "    print(pd.Series(y_train).value_counts())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('Test Value Counts')\n",
    "    print(pd.Series(y_test).value_counts())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('X Train Shape')\n",
    "    print(new_x_train.shape)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('X Test Shape')\n",
    "    print(new_x_test.shape)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    y_test = to_categorical(y_test)\n",
    "    y_train = to_categorical(y_train)\n",
    "    tts = (new_x_train, new_x_test, y_train, y_test)\n",
    "    return tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3969/3969 [00:06<00:00, 635.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 441/441 [00:00<00:00, 470.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Value Counts\n",
      "1    1368\n",
      "0    1368\n",
      "2    1233\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Test Value Counts\n",
      "1    152\n",
      "0    152\n",
      "2    137\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "X Train Shape\n",
      "(3969, 150, 150, 3)\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "X Test Shape\n",
      "(441, 150, 150, 3)\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = get_tts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uncomment the code below to see what the images look like\n",
    "cv2.imshow('test', x_train[25])\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model(dim = (150,150, 3)):\n",
    "    '''This function will create and compile a CNN given the input dimension'''\n",
    "    inp_shape = dim\n",
    "    act = 'relu'\n",
    "    drop = .25\n",
    "    kernal_reg = regularizers.l1(.001)\n",
    "    optimizer = Adam(lr = .0001)    \n",
    "    model = Sequential() \n",
    "    model.add(Conv2D(64, kernel_size=(3,3),activation=act, input_shape = inp_shape, \n",
    "                     kernel_regularizer = kernal_reg,\n",
    "                     kernel_initializer = 'he_uniform',  padding = 'same', name = 'Input_Layer'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),  strides = (3,3)))\n",
    "    model.add(Conv2D(64, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3))) \n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3)))  \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(3, activation='softmax', name = 'Output_Layer'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_Layer (Conv2D)         (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 50, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 860,547\n",
      "Trainable params: 860,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 105s 834ms/step - loss: 11.8835 - accuracy: 0.4715 - val_loss: 10.2455 - val_accuracy: 0.6780\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 10.24550, saving model to ModelWeights.h5\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 125s 1000ms/step - loss: 9.8279 - accuracy: 0.6560 - val_loss: 8.6502 - val_accuracy: 0.6961\n",
      "\n",
      "Epoch 00002: val_loss improved from 10.24550 to 8.65024, saving model to ModelWeights.h5\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 116s 927ms/step - loss: 8.2821 - accuracy: 0.7338 - val_loss: 7.4961 - val_accuracy: 0.6712\n",
      "\n",
      "Epoch 00003: val_loss improved from 8.65024 to 7.49610, saving model to ModelWeights.h5\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 105s 843ms/step - loss: 7.0908 - accuracy: 0.7366 - val_loss: 6.3481 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00004: val_loss improved from 7.49610 to 6.34814, saving model to ModelWeights.h5\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 100s 803ms/step - loss: 6.0940 - accuracy: 0.7579 - val_loss: 5.5953 - val_accuracy: 0.7483\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.34814 to 5.59532, saving model to ModelWeights.h5\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 102s 817ms/step - loss: 5.3422 - accuracy: 0.7818 - val_loss: 4.9813 - val_accuracy: 0.7324\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.59532 to 4.98134, saving model to ModelWeights.h5\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 99s 791ms/step - loss: 4.8105 - accuracy: 0.7715 - val_loss: 4.5172 - val_accuracy: 0.7483\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.98134 to 4.51723, saving model to ModelWeights.h5\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 101s 805ms/step - loss: 4.3823 - accuracy: 0.7827 - val_loss: 4.1890 - val_accuracy: 0.7415\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.51723 to 4.18904, saving model to ModelWeights.h5\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 106s 846ms/step - loss: 4.0671 - accuracy: 0.7899 - val_loss: 3.9792 - val_accuracy: 0.7324\n",
      "\n",
      "Epoch 00009: val_loss improved from 4.18904 to 3.97920, saving model to ModelWeights.h5\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 104s 835ms/step - loss: 3.8163 - accuracy: 0.8073 - val_loss: 3.7609 - val_accuracy: 0.7211\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.97920 to 3.76087, saving model to ModelWeights.h5\n"
     ]
    }
   ],
   "source": [
    "#prevents overfitting and saves models every time the validation loss improves\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=10, min_delta = .00075)\n",
    "model_checkpoint = ModelCheckpoint('ModelWeights.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 2, mode = 'min')\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "model = get_conv_model()\n",
    "model_history = model.fit(x_train, y_train, batch_size = batch_size,\n",
    "            epochs = epochs, \n",
    "     callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, overlapThresh= .5):\n",
    "    '''This image was taken from PyImageSearch... again cannot thank that guy enough'''\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1, y1, x2, y2 = boxes[:,0], boxes[:,1], boxes[:,2], boxes[:,3]    \n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1, yy1, xx2, yy2 = np.maximum(x1[i], x1[idxs[:last]]), np.maximum(y1[i], y1[idxs[:last]]), np.minimum(x2[i], x2[idxs[:last]]), np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w, h = np.maximum(0, xx2 - xx1 + 1), np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_prediction_bounding_box(path, model, dim):\n",
    "    '''This function will create a bounding box over what it believes is a weapon given the image path, dimensions, and model used to detect the weapon.  Dimensions can be found within the Var.py file.  This function is still being used as I need to apply non-max suppresion to create only one bounding box'''\n",
    "    img = get_image_value(path, dim)   \n",
    "    img = img.reshape(1, img.shape[0], img.shape[1], 3)\n",
    "    pred = model.predict(img)[0]\n",
    "    category_dict = {0: 'No Weapon', 1: 'Handgun', 2: 'Rifle'}\n",
    "    cat_index = np.argmax(pred)\n",
    "    cat = category_dict[cat_index]\n",
    "    print(f'{path}\\t\\tPrediction: {cat}\\t{int(pred.max()*100)}% Confident')\n",
    "\n",
    "    #speed up cv2\n",
    "    cv2.setUseOptimized(True)\n",
    "    cv2.setNumThreads(10) #change depending on your computer\n",
    "    img = cv2.imread(path)\n",
    "    clone = img.copy() \n",
    "    clone2 = img.copy()\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    ss.setBaseImage(img)\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "\n",
    "    rects = ss.process() \n",
    "    windows = []\n",
    "    locations = []\n",
    "    print(f'Creating Bounding Boxes for {path}')\n",
    "    for x, y, w,h in rects[:1001]: \n",
    "        startx, starty, endx, endy = x, y, x+w, y+h \n",
    "        roi = img[starty:endy, startx:endx]\n",
    "        roi = cv2.resize(roi, dsize =dim, interpolation = cv2.INTER_CUBIC)\n",
    "        windows.append(roi)\n",
    "        locations.append((startx, starty, endx, endy))\n",
    "    windows = np.array(windows)\n",
    "    windows = windows.reshape(windows.shape[0], windows.shape[1], windows.shape[2], 3)\n",
    "    windows = np.array(windows)\n",
    "    locations = np.array(locations)\n",
    "    predictions = model.predict(windows)\n",
    "    nms = non_max_suppression(locations)\n",
    "    bounding_cnt = 0\n",
    "    for idx in nms:\n",
    "        if np.argmax(predictions[idx]) != cat_index: \n",
    "            continue\n",
    "        startx, starty, endx, endy = locations[idx]\n",
    "        cv2.rectangle(clone, (startx, starty), (endx, endy), (0,0,255), 2)\n",
    "        text = f'{category_dict[np.argmax(predictions[idx])]}: {int(predictions[idx].max()*100)}%'\n",
    "        cv2.putText(clone, text, (startx, starty+15), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,255,0),2)\n",
    "        bounding_cnt += 1\n",
    "\n",
    "    if bounding_cnt == 0: \n",
    "        pred_idx= [idx for idx, i in enumerate(predictions) if np.argmax(i) == cat_index]\n",
    "        cat_locations = np.array([locations[i] for i in pred_idx])\n",
    "        nms = non_max_suppression(cat_locations)\n",
    "        if len(nms)==0:\n",
    "            cat_predictions = predictions[:,cat_index]\n",
    "            pred_max_idx = np.argmax(cat_predictions)\n",
    "            pred_max = cat_predictions[pred_max_idx]\n",
    "            pred_max_window = locations[pred_max_idx]\n",
    "            startx, starty, endx, endy = pred_max_window\n",
    "            cv2.rectangle(clone, (startx, starty), (endx, endy),  (0,0,255),2)\n",
    "            text = f'{category_dict[cat_index]}: {int(pred_max*100)}%'\n",
    "            cv2.putText(clone, text, (startx, starty+15), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,255,0),2)\n",
    "        for idx in nms: \n",
    "            startx, starty, endx, endy = cat_locations[idx]\n",
    "            cv2.rectangle(clone, (startx, starty), (endx, endy), (0,0,255), 2)\n",
    "            text = f'{category_dict[np.argmax(predictions[pred_idx[idx]])]}: {int(predictions[pred_idx[idx]].max()*100)}%'\n",
    "            cv2.putText(clone, text, (startx, starty+15), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,255,0),2)        \n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    cv2.imshow(f'Test', np.hstack([clone, clone2]))\n",
    "    cv2.waitKey(0)\n",
    "    ss.clear()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests/Pistol.jpg\t\tPrediction: Rifle\t59% Confident\n",
      "Creating Bounding Boxes for Tests/Pistol.jpg\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "#NORMAL MODEL\n",
    "dim = (150, 150, 3)    \n",
    "normal_model = get_conv_model(dim)\n",
    "normal_model.load_weights('ModelWeights.h5') #path to the model weights\n",
    "test_folder = 'Tests' #folder where you will put your images to test\n",
    "predictions = []\n",
    "for idx, i in enumerate([i for i in os.listdir(test_folder) if i != 'ipynb_checkpoints']):\n",
    "    img_path = f'{test_folder}/{i}'\n",
    "    pred = get_img_prediction_bounding_box(img_path, normal_model, dim = (150,150))\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests/Pistol.jpg\n"
     ]
    }
   ],
   "source": [
    "print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.4745098 , 0.87058824, 0.36078432],\n",
       "         [0.47843137, 0.8745098 , 0.3647059 ],\n",
       "         [0.4862745 , 0.87058824, 0.3254902 ],\n",
       "         ...,\n",
       "         [0.52156866, 0.9019608 , 0.34509805],\n",
       "         [0.52156866, 0.9098039 , 0.34901962],\n",
       "         [0.52156866, 0.9098039 , 0.34901962]],\n",
       "\n",
       "        [[0.4745098 , 0.8745098 , 0.34117648],\n",
       "         [0.47843137, 0.8784314 , 0.34509805],\n",
       "         [0.4862745 , 0.87058824, 0.3254902 ],\n",
       "         ...,\n",
       "         [0.52156866, 0.9019608 , 0.34509805],\n",
       "         [0.52156866, 0.9098039 , 0.34901962],\n",
       "         [0.52156866, 0.9098039 , 0.34901962]],\n",
       "\n",
       "        [[0.47058824, 0.8745098 , 0.3137255 ],\n",
       "         [0.4745098 , 0.8784314 , 0.31764707],\n",
       "         [0.48235294, 0.8666667 , 0.32156864],\n",
       "         ...,\n",
       "         [0.5176471 , 0.8980392 , 0.34117648],\n",
       "         [0.52156866, 0.9098039 , 0.34901962],\n",
       "         [0.5137255 , 0.9019608 , 0.34117648]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4       , 0.8039216 , 0.2509804 ],\n",
       "         [0.41960785, 0.8235294 , 0.27058825],\n",
       "         [0.42352942, 0.8235294 , 0.2901961 ],\n",
       "         ...,\n",
       "         [0.43137255, 0.3254902 , 0.24313726],\n",
       "         [0.43529412, 0.33333334, 0.23529412],\n",
       "         [0.46666667, 0.3647059 , 0.26666668]],\n",
       "\n",
       "        [[0.40784314, 0.8117647 , 0.25882354],\n",
       "         [0.4117647 , 0.8156863 , 0.2627451 ],\n",
       "         [0.42352942, 0.8235294 , 0.2901961 ],\n",
       "         ...,\n",
       "         [0.42352942, 0.31764707, 0.23529412],\n",
       "         [0.4509804 , 0.34901962, 0.2509804 ],\n",
       "         [0.4509804 , 0.34901962, 0.2509804 ]],\n",
       "\n",
       "        [[0.40784314, 0.8117647 , 0.25882354],\n",
       "         [0.40392157, 0.80784315, 0.25490198],\n",
       "         [0.4117647 , 0.8117647 , 0.2784314 ],\n",
       "         ...,\n",
       "         [0.42352942, 0.31764707, 0.23529412],\n",
       "         [0.4392157 , 0.3372549 , 0.23921569],\n",
       "         [0.4509804 , 0.34901962, 0.2509804 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = get_image_value(img_path, dim)   \n",
    "img = img.reshape(1, img.shape[0], img.shape[1], 3)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00624396, 0.39715645, 0.5965996 ], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_try = normal_model.predict(img)[0]\n",
    "pred_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_dict = {0: 'No Weapon', 1: 'Handgun', 2: 'Rifle'}\n",
    "cat_index = np.argmax(pred)\n",
    "cat_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No Weapon'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = category_dict[cat_index]\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
